{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eff767e",
   "metadata": {},
   "source": [
    "## **Urdu Sentence Annotation for Hate Speech Detection**"
   ]
  },  
  {
   "cell_type": "markdown",
   "id": "2eff767e",
   "metadata": {},
   "source": [
    "### **Data Collection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd552599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "from googleapiclient.discovery import build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a52d7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 771 Nastaliq Urdu comments! Saved to nastaliq_urdu_youtube_comments.csv\n"
     ]
    }
   ],
   "source": [
    "# Setup YouTube API\n",
    "api_key = 'api key'  # <-- Put your YouTube Data API v3 key here\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "# List of video URLs\n",
    "video_urls = [\n",
    "    \"https://www.youtube.com/watch?v=B85_wZF7XCY\",\n",
    "    \"https://www.youtube.com/watch?v=vSQeAgGUA80\",   \n",
    "    \"https://www.youtube.com/watch?v=sCjNi75u-y4\",   \n",
    "    \"https://www.youtube.com/watch?v=oHEs19lx0ZU\",   \n",
    "    \"https://www.youtube.com/watch?v=8LpGOBQxwhU\",   \n",
    "    \"https://www.youtube.com/watch?v=-0jcXcN7F_I\",\n",
    "    \"https://www.youtube.com/watch?v=WNfzFSSRGrU\",\n",
    "    \"https://www.youtube.com/watch?v=4zzsVCsTxGU\",   \n",
    "    \"https://www.youtube.com/watch?v=0f2RTcz9Dho\" \n",
    "]\n",
    "\n",
    "# Urdu script detector\n",
    "def is_urdu_nastaliq(text, threshold=0.6):\n",
    "    urdu_chars = re.findall(r'[\\u0600-\\u06FF]', text)\n",
    "    return len(urdu_chars) / max(len(text), 1) >= threshold\n",
    "\n",
    "comments = []\n",
    "\n",
    "# Fetch comments\n",
    "for video_url in video_urls:\n",
    "    video_id = video_url.split('v=')[1]\n",
    "    nextPageToken = None\n",
    "    try:\n",
    "        while True:\n",
    "            response = youtube.commentThreads().list(\n",
    "                part=\"snippet\",\n",
    "                videoId=video_id,\n",
    "                pageToken=nextPageToken,\n",
    "                maxResults=100,\n",
    "                textFormat=\"plainText\"\n",
    "            ).execute()\n",
    "\n",
    "            for item in response['items']:\n",
    "                comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "                if comment and len(comment) > 15 and is_urdu_nastaliq(comment):\n",
    "                    comments.append(comment)\n",
    "\n",
    "            nextPageToken = response.get('nextPageToken')\n",
    "            if not nextPageToken:\n",
    "                break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching comments for {video_url}: {e}\")\n",
    "\n",
    "# Shuffle and pick top 300\n",
    "comments = list(set(comments))\n",
    "random.shuffle(comments)\n",
    "selected_comments = comments[:1000]\n",
    "\n",
    "# Save\n",
    "df = pd.DataFrame(selected_comments, columns=[\"comments\"])\n",
    "df.to_csv(\"nastaliq_urdu_youtube_comments.csv\", index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Scraped {len(selected_comments)} Nastaliq Urdu comments! Saved to nastaliq_urdu_youtube_comments.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74ed923",
   "metadata": {},
   "source": [
    "### **Data Preprocessing**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bcfcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete. Saved 1032 clean Urdu comments to preprocessed_urdu_youtube_comments.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV\n",
    "df = pd.read_csv(\"nastaliq_urdu_youtube_comments.csv\", encoding='utf-8-sig')\n",
    "\n",
    "# Emoji pattern\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "    u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "    u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "    u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "    u\"\\U0001F1E0-\\U0001F1FF\"  # flags\n",
    "    u\"\\U00002700-\\U000027BF\"  # Dingbats\n",
    "    u\"\\U000024C2-\\U0001F251\"  # Enclosed characters\n",
    "\"]+\", flags=re.UNICODE)\n",
    "\n",
    "# Urdu characters range (removes Arabic letters not used in Urdu)\n",
    "urdu_allowed = r'\\u0600-\\u06FF'\n",
    "# Remove unwanted Arabic supplement, digits, Latin, etc.\n",
    "def preprocess_comment(text):\n",
    "    # Remove emojis\n",
    "    text = emoji_pattern.sub('', text)\n",
    "    # Remove English, digits, punctuation, etc.\n",
    "    text = re.sub(r'[a-zA-Z0-9@#%^&*()_+=\\[\\]{}|\\\\:;\"\\'<>,./?!~`–“”\\'\\\"]+', ' ', text)\n",
    "    # Remove Arabic Presentation Forms (non-Nastaliq Arabic glyphs)\n",
    "    text = re.sub(r'[\\u0750-\\u077F\\u08A0-\\u08FF\\uFB50-\\uFDFF\\uFE70-\\uFEFF]', ' ', text)\n",
    "    # Keep only Nastaliq Urdu characters and spaces\n",
    "    text = re.sub(f'[^{urdu_allowed} ]+', ' ', text)\n",
    "    # Normalize whitespace\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "# Apply preprocessing\n",
    "df['cleaned'] = df['comments'].astype(str).apply(preprocess_comment)\n",
    "\n",
    "# Drop empty rows after cleaning\n",
    "df = df[df['cleaned'].str.strip() != '']\n",
    "\n",
    "# Save\n",
    "df[['cleaned']].to_csv(\"preprocessed_urdu_youtube_comments.csv\", index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Preprocessing complete. Saved {len(df)} clean Urdu comments to preprocessed_urdu_youtube_comments.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae17a075",
   "metadata": {},
   "source": [
    "### **Annotation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32ed489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 'h' for Hate Speech, 'o' for Offensive, 'n' for Neutral.\n",
      "----------------------------------------------------------\n",
      "\n",
      "Comment 1:\n",
      "اپنا آئی ایم ایف والا قرضہ دے کر مرنا نہیں تو تمہارے حصے کا ہمیں بھرنا پڑے گا\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comment 2:\n",
      "ڈکی حرامخور ہیرا منڈی کی پیداوار ہے لعنت تیری نسل پر جھوٹے\n",
      "\n",
      "Comment 3:\n",
      "ایک میاں جہنم میں جائے گا اپنی بیوی کو منع نہیں کرتا بھائی جان میں جائے گا باپ باب جہنم میں جائے گا ماں جہنم میں جائے گی جو منع نہیں کرتی پردے کا باقی اپ کی موج ہے بے حیائی پھیلاتے جائیں اپ کو بہت ثواب ملے گا بے حیائی پھیلاتے جائیں بالکل منع نہ کریں\n",
      "\n",
      "Comment 4:\n",
      "شامیر بھی گانڈو ہے اور شام بھی بس فروگی اچھی ہے\n",
      "\n",
      "Comment 5:\n",
      "بہن سے کبھی ادھار مت لینا لیا تھا بار دے چکا ہوں ابھی بھی باقی ہے\n",
      "\n",
      "Comment 6:\n",
      "محنت تو بھکاری بھی کرتے ہیں اور ڈاکو بھی۔آخر اِنکی محنت کیوں کِسی کو نظر نہیں آتی ؟\n",
      "\n",
      "Comment 7:\n",
      "لکھتے قلم ختم ہو جائے گی لیکن میرے نبی کی شان کبھی کم نہیں ہوگی\n",
      "\n",
      "Comment 8:\n",
      "ڈکی بھائی آپ ولوگ شروع کرے ہم آپ کے ساتھ ہے\n",
      "\n",
      "Comment 9:\n",
      "ڈٹے رہو ڈکی بھائ\n",
      "\n",
      "Comment 10:\n",
      "اِنَرَبِّیِ یَفعَلُمَا یَشَاَءُ بیشک میرا رب جو چاھے، کر سکتا ھے\n",
      "\n",
      "Comment 11:\n",
      "ہر بےعزتی والے کمنٹس پر ڈھیٹ بن کر ہنس رہے ہیں\n",
      "\n",
      "Comment 12:\n",
      "آپ بی اپنا کام اچھا کرو ۔ ہر وقت دوسرے کی عزت اڑاتے ہو بس۔\n",
      "\n",
      "Comment 13:\n",
      "اللہ نہ کرے شہزادے آپ کو کچھ ھو اللہ اپنی امان میں رکھے آمین اللہ آمین\n",
      "\n",
      "Comment 14:\n",
      "اللہ تعالیٰ آپ کو اولاد کی نعمت عطاء فرمائے آمین\n",
      "\n",
      "Comment 15:\n",
      "لکھتے قلم ختم ہو جائے گی لیکن میرے نبی کی شان کبھی کم نہیں ہوگی ۔\n",
      "\n",
      "Comment 16:\n",
      "تم لوگوں کا آپس میں کیا ہوا ، لڑائی کیوں ہوئی ؟ اس کے بعد تم نے لوگوں نے ایک دوسرے کے خلاف کیا کیا ؟ میرا خیال ہے کہ یہ کسی بھی دیکھنے والے کا موضوع نہیں ہونا چاہئیے ۔۔۔ حقیقت اور سچ یہی ہے کہ ، تم لوگوں نے اپنے دیکھنے والوں کو دھوکہ دینے کی کوشش کی ہے ۔۔۔۔ اور اس کو پورا پلان کیا ہے ۔۔۔۔ اب اس میں کوئی کتنا قصوروار تھا ۔۔۔۔ یہ معنی نہیں رکھتا ۔۔۔۔ تم لوگوں نے مل کے پلان بنایا ۔۔۔۔ تو تم سب برابر کے دمہ دار ہو ۔۔۔ اس بات پر شرمندہ ہونے کی بجائے باقی کہانیاں سنا رہے ہو اور اصل قصور کو مان نہیں رہے ۔۔۔ ارے بھائی ہمیں کیا غرض کہ طلحہ ، ندیم یا شام کے درمیان لڑائی کیوں ہے ؟؟؟ ہمارا مطلب یہ کہ تم لوگوں کو شرم نہیں آئی دیکھنے والوں کے خلاف پلان بناتے ہوئے ۔۔۔۔۔ اس بات پر شرم کرو بے شرمو۔۔۔۔۔۔\n",
      "\n",
      "Comment 17:\n",
      "شام خبیث بھائی جان۔۔۔ اب آپ پکا وڑ گئے ہو اور یہ ویڈیو آپکے تابوت میں آخری کیل ہے۔\n",
      "\n",
      "Comment 18:\n",
      "تم سب بھڑوت کہا رہے ھو\n",
      "\n",
      "Comment 19:\n",
      "ان بھکاریوں سےبہتر دین کی معلومات میں اضافہ کریں۔\n",
      "\n",
      "Comment 20:\n",
      "سعد بھائی میں لاہور سے ہوں جب بھی لاہور آئیں پلیز مجھ سے ضرور ملئیے گا۔ میں نے آج ہی آپ کا چینل سبسکرائب کیا ہے۔ لو یو برو\n",
      "\n",
      "Comment 21:\n",
      "یار ان کتوں کی بھی لوگ سنتے ہیں حد ہے ویسے\n",
      "\n",
      "Comment 22:\n",
      "یہ دونوں چوتیے ہیں\n",
      "\n",
      "Comment 23:\n",
      "لوگوں نے ان سبسکرائب تو ایسے کیا جیسے کبھی اپ سے پیار ہی نہیں کیا تھا جب بھی ایک ملین ہوا اس نے اپنے بال کاٹے اس نے لوگوں کو بہت انٹرٹینمنٹ کیا\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "input_file = 'preprocessed_urdu_youtube_comments.csv'\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Add a new column for annotations\n",
    "df['label'] = ''\n",
    "\n",
    "print(\"Type 'h' for Hate Speech, 'o' for Offensive, 'n' for Neutral.\")\n",
    "print(\"----------------------------------------------------------\")\n",
    "\n",
    "# Loop through each comment\n",
    "for idx, row in df.iterrows():\n",
    "    print(f\"\\nComment {idx + 1}:\")\n",
    "    print(row['cleaned'])\n",
    "\n",
    "    while True:\n",
    "        annotation = input(\"Enter annotation (h/o/n): \").strip().lower()\n",
    "        if annotation in ['h', 'o', 'n']:\n",
    "            df.at[idx, 'Annotation'] = annotation\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid input. Please enter 'h', 'o', or 'n'.\")\n",
    "\n",
    "# Save the annotated file\n",
    "output_file = 'annotated_dataset.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\nAnnotation complete! Saved as '{output_file}'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rizzy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
